{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f608ac4e-1d57-4937-beb9-d352c9657ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# üîß Configuration\n",
    "API_KEY = \"\"  # your API key\n",
    "CAMPAIGN_ID =   # your Yandex Market campaign ID\n",
    "\n",
    "# üóìÔ∏è Automatically get last month and year\n",
    "today = datetime.today()\n",
    "first_day_this_month = today.replace(day=1)\n",
    "last_month_date = first_day_this_month - timedelta(days=1)\n",
    "MONTH = str(last_month_date.month)   # previous month as number\n",
    "YEAR = str(last_month_date.year)     # year of that previous month\n",
    "\n",
    "print(f\"üìÖ Automatically selected period: {MONTH}/{YEAR}\")\n",
    "\n",
    "BASE_URL = \"https://api.partner.market.yandex.ru/v2/reports/goods-realization\"\n",
    "HEADERS = {\"Api-Key\": API_KEY}\n",
    "\n",
    "# Step 1: Generate report\n",
    "payload = {\n",
    "    \"campaignId\": CAMPAIGN_ID,\n",
    "    \"month\": MONTH,\n",
    "    \"year\": YEAR\n",
    "}\n",
    "\n",
    "print(f\"üì§ Generating 'goods-realization' report for {MONTH}/{YEAR}...\")\n",
    "response = requests.post(f\"{BASE_URL}/generate\", headers=HEADERS, json=payload)\n",
    "\n",
    "if response.status_code != 200:\n",
    "    raise Exception(f\"‚ùå Failed to generate report: {response.text}\")\n",
    "\n",
    "report_id = response.json()[\"result\"][\"reportId\"]\n",
    "print(f\"‚úÖ Report requested. ID: {report_id}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5deba9-c474-497d-a024-85bf0743c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# üîß Configuration\n",
    "API_KEY = \"\"  # your API key\n",
    "REPORT_ID = report_id  # replace with your actual reportId\n",
    "SAVE_PATH = r\"\"\n",
    "\n",
    "# Fixed filename\n",
    "FIXED_FILENAME = \"\"\n",
    "\n",
    "# API endpoint\n",
    "url = f\"https://api.partner.market.yandex.ru/v2/reports/info/{REPORT_ID}\"\n",
    "headers = {\"Api-Key\": API_KEY}\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# üßæ Fetch report info\n",
    "# ------------------------------------------------------------\n",
    "print(f\"üìÑ Fetching info for report ID: {REPORT_ID} ...\")\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code != 200:\n",
    "    raise Exception(f\"‚ùå Failed to get report info: {response.text}\")\n",
    "\n",
    "data = response.json()\n",
    "print(\"‚úÖ Report Info retrieved.\")\n",
    "\n",
    "# Extract download link\n",
    "report_info = data.get(\"result\", {})\n",
    "file_url = report_info.get(\"file\")\n",
    "\n",
    "if not file_url:\n",
    "    raise Exception(\"‚ö†Ô∏è Report file link not found in response.\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# ‚¨áÔ∏è Download report\n",
    "# ------------------------------------------------------------\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "file_path = os.path.join(SAVE_PATH, FIXED_FILENAME)\n",
    "\n",
    "print(f\"‚¨áÔ∏è Downloading report to: {file_path}\")\n",
    "file_response = requests.get(file_url)\n",
    "\n",
    "if file_response.status_code == 200:\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(file_response.content)\n",
    "    print(f\"‚úÖ Report downloaded successfully: {file_path}\")\n",
    "else:\n",
    "    raise Exception(f\"‚ùå Failed to download report file: {file_response.text}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# üßπ Clean and keep only desired data\n",
    "# ------------------------------------------------------------\n",
    "try:\n",
    "    wb = load_workbook(file_path)\n",
    "    sheet_to_keep = \"–î–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã\"\n",
    "\n",
    "    if sheet_to_keep in wb.sheetnames:\n",
    "        for sheet in wb.sheetnames:\n",
    "            if sheet != sheet_to_keep:\n",
    "                del wb[sheet]\n",
    "\n",
    "        ws = wb[sheet_to_keep]\n",
    "\n",
    "        # ‚úÖ Step 1: Unmerge all merged cells and fill their values\n",
    "        merged_ranges = list(ws.merged_cells.ranges)\n",
    "        for merged_range in merged_ranges:\n",
    "            top_left_cell = ws.cell(row=merged_range.min_row, column=merged_range.min_col)\n",
    "            value = top_left_cell.value\n",
    "            ws.unmerge_cells(str(merged_range))\n",
    "            for row in ws.iter_rows(min_row=merged_range.min_row, max_row=merged_range.max_row,\n",
    "                                    min_col=merged_range.min_col, max_col=merged_range.max_col):\n",
    "                for cell in row:\n",
    "                    cell.value = value\n",
    "        print(\"üîÑ Unmerged all merged cells and filled values.\")\n",
    "\n",
    "        # üßΩ Step 2: Delete the first 16 rows\n",
    "        ws.delete_rows(1, 16)\n",
    "        print(\"üßΩ Deleted the first 16 rows.\")\n",
    "\n",
    "        # ‚úÖ Step 3: Keep only specific columns\n",
    "        keep_columns = [\n",
    "            \"–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞\",\n",
    "            \"–î–æ—Å—Ç–∞–≤–ª–µ–Ω–æ, —à—Ç.\",\n",
    "            \"–î–∞—Ç–∞ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è –∑–∞–∫–∞–∑–∞\",\n",
    "            \"–°—Ç–æ–∏–º–æ—Å—Ç—å –≤—Å–µ—Ö –¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö —à—Ç—É–∫ —Å –ù–î–° –±–µ–∑ —É—á—ë—Ç–∞ —Å–∫–∏–¥–æ–∫, ‚ÇΩ\"\n",
    "        ]\n",
    "\n",
    "        header_row = [cell.value for cell in ws[1]]\n",
    "        keep_indexes = [i + 1 for i, col_name in enumerate(header_row) if col_name in keep_columns]\n",
    "\n",
    "        if not keep_indexes:\n",
    "            print(\"‚ö†Ô∏è None of the specified columns were found in the sheet.\")\n",
    "        else:\n",
    "            for i in range(ws.max_column, 0, -1):\n",
    "                if i not in keep_indexes:\n",
    "                    ws.delete_cols(i)\n",
    "            print(f\"üßπ Kept only selected columns: {keep_columns}\")\n",
    "\n",
    "        # üöÆ Step 4: Remove empty rows (where product name is None)\n",
    "        rows_to_delete = []\n",
    "        for row in range(ws.max_row, 1, -1):\n",
    "            if not ws.cell(row=row, column=1).value:\n",
    "                rows_to_delete.append(row)\n",
    "        for row in rows_to_delete:\n",
    "            ws.delete_rows(row)\n",
    "        print(f\"üßº Removed {len(rows_to_delete)} empty rows.\")\n",
    "\n",
    "        # üíæ Save workbook\n",
    "        wb.save(file_path)\n",
    "        print(f\"‚úÖ Final file with 'Sales' column saved: {file_path}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è '{sheet_to_keep}' not found in workbook. No sheets removed.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Failed to modify workbook: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9203e70f-422c-40b0-866b-79f377ff7f50",
   "metadata": {},
   "source": [
    "## Appending Final Output to sharepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce738616-dc7d-4aba-9e34-0df7b9d3ea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from office365.sharepoint.client_context import ClientContext\n",
    "from office365.sharepoint.files.file import File\n",
    "from office365.runtime.auth.client_credential import ClientCredential\n",
    "\n",
    "# SharePoint link and file details\n",
    "site_url = ''\n",
    "doc_library = ''\n",
    "file_name = ''\n",
    "\n",
    "# Client ID & Secret\n",
    "client_id = \"\"\n",
    "client_secret = \"\"\n",
    "\n",
    "# Define the path to your local Excel file containing the new data\n",
    "new_data_file_path = r\"\"\n",
    "\n",
    "# Define the columns to check for duplicates\n",
    "subset_columns = [\n",
    "    '–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞', '–î–æ—Å—Ç–∞–≤–ª–µ–Ω–æ, —à—Ç.', '–î–∞—Ç–∞ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è –∑–∞–∫–∞–∑–∞', '–°—Ç–æ–∏–º–æ—Å—Ç—å –≤—Å–µ—Ö –¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö —à—Ç—É–∫ —Å –ù–î–° –±–µ–∑ —É—á—ë—Ç–∞ —Å–∫–∏–¥–æ–∫, ‚ÇΩ']\n",
    "\n",
    "try:\n",
    "    # Authenticate using Client ID & Secret\n",
    "    credentials = ClientCredential(client_id, client_secret)\n",
    "    ctx = ClientContext(site_url).with_credentials(credentials)\n",
    "    ctx.load(ctx.web)\n",
    "    ctx.execute_query()\n",
    "    print(\"‚úÖ Connected to SharePoint:\", ctx.web.properties['Title'])\n",
    "\n",
    "    # Download the existing file from SharePoint\n",
    "    response = File.open_binary(ctx, f\"{doc_library}/{file_name}\")\n",
    "\n",
    "    # Write the response content to a local file\n",
    "    with open(file_name, \"wb\") as existing_file:\n",
    "        existing_file.write(response.content)\n",
    "\n",
    "    print(\"Existing file has been downloaded from SharePoint.\")\n",
    "\n",
    "    # Load the existing data into a DataFrame\n",
    "    try:\n",
    "        existing_df = pd.read_excel(file_name)\n",
    "        print(\"Existing data loaded into DataFrame.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading existing data: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during file download for existing data: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Load the new data into a DataFrame\n",
    "try:\n",
    "    df = pd.read_excel(new_data_file_path)\n",
    "    print(\"New data loaded into DataFrame.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading new data from the file: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Combine the existing data with the new data\n",
    "try:\n",
    "    # Combine and deduplicate based on the subset columns\n",
    "    combined_df = pd.concat([existing_df, df], ignore_index=True)\n",
    "    combined_df = combined_df.drop_duplicates(subset=subset_columns)\n",
    "    print(\"New data merged with existing data successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error while merging data: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Get the new rows added after combining\n",
    "new_rows = combined_df[len(existing_df):]\n",
    "\n",
    "if new_rows.empty:\n",
    "    print(\"No new rows to add.\")\n",
    "else:\n",
    "    # Append the new rows to the Excel sheet\n",
    "    try:\n",
    "        book = load_workbook(file_name)\n",
    "        sheet = book['–î–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã']  # Pls check that this matches your sheet name\n",
    "        for row in new_rows.itertuples(index=False, name=None):\n",
    "            sheet.append(row)\n",
    "\n",
    "        # Save the modified file\n",
    "        book.save(file_name)\n",
    "        print(\"Data has been successfully written to the Excel file without duplicates.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving the Excel file: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "    # Upload the updated file back to SharePoint\n",
    "    try:\n",
    "        with open(file_name, 'rb') as content_file:\n",
    "            file_content = content_file.read()\n",
    "\n",
    "        File.save_binary(ctx, f\"{doc_library}/{file_name}\", file_content)\n",
    "        print(\"File has been uploaded back to SharePoint.\")\n",
    "        print(\"Everything Completed\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during file upload: {e}\")\n",
    "\n",
    "# Cleanup: Remove the local file\n",
    "if os.path.exists(file_name):\n",
    "    os.remove(file_name)\n",
    "    print(\"Local file has been deleted.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
