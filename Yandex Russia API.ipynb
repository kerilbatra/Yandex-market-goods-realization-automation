{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea90ecca-ee71-4981-af67-1b2301e162bd",
   "metadata": {},
   "source": [
    "## API TOKEN = 'ACMA:RdrFYjCf8O1BgKW2vsiI5FltiHKfmq7SOYyOBFE0:be01dcf1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3a0007-7173-424f-b38a-26bad9e52f09",
   "metadata": {},
   "source": [
    "## Extracting Sales Data Using Yandex API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c1da66-8d0d-45e3-a4dc-87593f007a1e",
   "metadata": {},
   "source": [
    "## https://yandex.ru/dev/market/partner-api/doc/ru/api/reports/generateGoodsRealizationReport?tabs=defaultTabsGroup-jqgkfhps_info%2CdefaultTabsGroup-yjmjyv4h_fby%252c%2520fbs%252c%2520%25d0%25ad%25d0%25ba%25d1%2581%25d0%25bf%25d1%2580%25d0%25b5%25d1%2581%25d1%2581"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b097d5af-c28b-4ae7-a1f4-6fb5869836fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Automatically selected period: 10/2025\n",
      "üì§ Generating 'goods-realization' report for 10/2025...\n",
      "‚úÖ Report requested. ID: 8b03920f-b371-433d-9837-4f801010cd7c\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# üîß Configuration\n",
    "API_KEY = \"ACMA:RdrFYjCf8O1BgKW2vsiI5FltiHKfmq7SOYyOBFE0:be01dcf1\"  # your API key\n",
    "CAMPAIGN_ID = 148649267  # your Yandex Market campaign ID\n",
    "\n",
    "# üóìÔ∏è Automatically get last month and year\n",
    "today = datetime.today()\n",
    "first_day_this_month = today.replace(day=1)\n",
    "last_month_date = first_day_this_month - timedelta(days=1)\n",
    "MONTH = str(last_month_date.month)   # previous month as number\n",
    "YEAR = str(last_month_date.year)     # year of that previous month\n",
    "\n",
    "print(f\"üìÖ Automatically selected period: {MONTH}/{YEAR}\")\n",
    "\n",
    "BASE_URL = \"https://api.partner.market.yandex.ru/v2/reports/goods-realization\"\n",
    "HEADERS = {\"Api-Key\": API_KEY}\n",
    "\n",
    "# Step 1: Generate report\n",
    "payload = {\n",
    "    \"campaignId\": CAMPAIGN_ID,\n",
    "    \"month\": MONTH,\n",
    "    \"year\": YEAR\n",
    "}\n",
    "\n",
    "print(f\"üì§ Generating 'goods-realization' report for {MONTH}/{YEAR}...\")\n",
    "response = requests.post(f\"{BASE_URL}/generate\", headers=HEADERS, json=payload)\n",
    "\n",
    "if response.status_code != 200:\n",
    "    raise Exception(f\"‚ùå Failed to generate report: {response.text}\")\n",
    "\n",
    "report_id = response.json()[\"result\"][\"reportId\"]\n",
    "print(f\"‚úÖ Report requested. ID: {report_id}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b4c602d-7f0d-4227-93b4-f79f0c89c0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Fetching info for report ID: 460a792c-b397-42ae-8388-61a68742a214 ...\n",
      "‚úÖ Report Info retrieved.\n",
      "‚¨áÔ∏è Downloading report to: C:\\Users\\keril.batra\\OneDrive - Herbion\\Desktop\\E-Commerce\\Russia Yandex\\RU-Yandex Sales.xlsx\n",
      "‚úÖ Report downloaded successfully: C:\\Users\\keril.batra\\OneDrive - Herbion\\Desktop\\E-Commerce\\Russia Yandex\\RU-Yandex Sales.xlsx\n",
      "üîÑ Unmerged all merged cells and filled values.\n",
      "üßΩ Deleted the first 16 rows.\n",
      "üßπ Kept only selected columns: ['–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞', '–î–æ—Å—Ç–∞–≤–ª–µ–Ω–æ, —à—Ç.', '–î–∞—Ç–∞ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è –∑–∞–∫–∞–∑–∞', '–°—Ç–æ–∏–º–æ—Å—Ç—å –≤—Å–µ—Ö –¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö —à—Ç—É–∫ —Å –ù–î–° –±–µ–∑ —É—á—ë—Ç–∞ —Å–∫–∏–¥–æ–∫, ‚ÇΩ']\n",
      "üßº Removed 1 empty rows.\n",
      "‚úÖ Final file with 'Sales' column saved: C:\\Users\\keril.batra\\OneDrive - Herbion\\Desktop\\E-Commerce\\Russia Yandex\\RU-Yandex Sales.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# üîß Configuration\n",
    "API_KEY = \"ACMA:RdrFYjCf8O1BgKW2vsiI5FltiHKfmq7SOYyOBFE0:be01dcf1\"  # your API key\n",
    "REPORT_ID = report_id  # replace with your actual reportId\n",
    "SAVE_PATH = r\"C:\\Users\\keril.batra\\OneDrive - Herbion\\Desktop\\E-Commerce\\Russia Yandex\"\n",
    "\n",
    "# Fixed filename\n",
    "FIXED_FILENAME = \"RU-Yandex Sales.xlsx\"\n",
    "\n",
    "# API endpoint\n",
    "url = f\"https://api.partner.market.yandex.ru/v2/reports/info/{REPORT_ID}\"\n",
    "headers = {\"Api-Key\": API_KEY}\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# üßæ Fetch report info\n",
    "# ------------------------------------------------------------\n",
    "print(f\"üìÑ Fetching info for report ID: {REPORT_ID} ...\")\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code != 200:\n",
    "    raise Exception(f\"‚ùå Failed to get report info: {response.text}\")\n",
    "\n",
    "data = response.json()\n",
    "print(\"‚úÖ Report Info retrieved.\")\n",
    "\n",
    "# Extract download link\n",
    "report_info = data.get(\"result\", {})\n",
    "file_url = report_info.get(\"file\")\n",
    "\n",
    "if not file_url:\n",
    "    raise Exception(\"‚ö†Ô∏è Report file link not found in response.\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# ‚¨áÔ∏è Download report\n",
    "# ------------------------------------------------------------\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "file_path = os.path.join(SAVE_PATH, FIXED_FILENAME)\n",
    "\n",
    "print(f\"‚¨áÔ∏è Downloading report to: {file_path}\")\n",
    "file_response = requests.get(file_url)\n",
    "\n",
    "if file_response.status_code == 200:\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(file_response.content)\n",
    "    print(f\"‚úÖ Report downloaded successfully: {file_path}\")\n",
    "else:\n",
    "    raise Exception(f\"‚ùå Failed to download report file: {file_response.text}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# üßπ Clean and keep only desired data\n",
    "# ------------------------------------------------------------\n",
    "try:\n",
    "    wb = load_workbook(file_path)\n",
    "    sheet_to_keep = \"–î–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã\"\n",
    "\n",
    "    if sheet_to_keep in wb.sheetnames:\n",
    "        for sheet in wb.sheetnames:\n",
    "            if sheet != sheet_to_keep:\n",
    "                del wb[sheet]\n",
    "\n",
    "        ws = wb[sheet_to_keep]\n",
    "\n",
    "        # ‚úÖ Step 1: Unmerge all merged cells and fill their values\n",
    "        merged_ranges = list(ws.merged_cells.ranges)\n",
    "        for merged_range in merged_ranges:\n",
    "            top_left_cell = ws.cell(row=merged_range.min_row, column=merged_range.min_col)\n",
    "            value = top_left_cell.value\n",
    "            ws.unmerge_cells(str(merged_range))\n",
    "            for row in ws.iter_rows(min_row=merged_range.min_row, max_row=merged_range.max_row,\n",
    "                                    min_col=merged_range.min_col, max_col=merged_range.max_col):\n",
    "                for cell in row:\n",
    "                    cell.value = value\n",
    "        print(\"üîÑ Unmerged all merged cells and filled values.\")\n",
    "\n",
    "        # üßΩ Step 2: Delete the first 16 rows\n",
    "        ws.delete_rows(1, 16)\n",
    "        print(\"üßΩ Deleted the first 16 rows.\")\n",
    "\n",
    "        # ‚úÖ Step 3: Keep only specific columns\n",
    "        keep_columns = [\n",
    "            \"–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞\",\n",
    "            \"–î–æ—Å—Ç–∞–≤–ª–µ–Ω–æ, —à—Ç.\",\n",
    "            \"–î–∞—Ç–∞ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è –∑–∞–∫–∞–∑–∞\",\n",
    "            \"–°—Ç–æ–∏–º–æ—Å—Ç—å –≤—Å–µ—Ö –¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö —à—Ç—É–∫ —Å –ù–î–° –±–µ–∑ —É—á—ë—Ç–∞ —Å–∫–∏–¥–æ–∫, ‚ÇΩ\"\n",
    "        ]\n",
    "\n",
    "        header_row = [cell.value for cell in ws[1]]\n",
    "        keep_indexes = [i + 1 for i, col_name in enumerate(header_row) if col_name in keep_columns]\n",
    "\n",
    "        if not keep_indexes:\n",
    "            print(\"‚ö†Ô∏è None of the specified columns were found in the sheet.\")\n",
    "        else:\n",
    "            for i in range(ws.max_column, 0, -1):\n",
    "                if i not in keep_indexes:\n",
    "                    ws.delete_cols(i)\n",
    "            print(f\"üßπ Kept only selected columns: {keep_columns}\")\n",
    "\n",
    "        # üöÆ Step 4: Remove empty rows (where product name is None)\n",
    "        rows_to_delete = []\n",
    "        for row in range(ws.max_row, 1, -1):\n",
    "            if not ws.cell(row=row, column=1).value:\n",
    "                rows_to_delete.append(row)\n",
    "        for row in rows_to_delete:\n",
    "            ws.delete_rows(row)\n",
    "        print(f\"üßº Removed {len(rows_to_delete)} empty rows.\")\n",
    "\n",
    "        # üíæ Save workbook\n",
    "        wb.save(file_path)\n",
    "        print(f\"‚úÖ Final file with 'Sales' column saved: {file_path}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è '{sheet_to_keep}' not found in workbook. No sheets removed.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Failed to modify workbook: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb79ca82-2888-4c44-a25b-a34a438ad504",
   "metadata": {},
   "source": [
    "## Appending Data on Sharepoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9bf16720-ba49-49c5-b3f5-24a0e3ee9f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to SharePoint: Power BI\n",
      "Existing file has been downloaded from SharePoint.\n",
      "Existing data loaded into DataFrame.\n",
      "New data loaded into DataFrame.\n",
      "New data merged with existing data successfully.\n",
      "Data has been successfully written to the Excel file without duplicates.\n",
      "File has been uploaded back to SharePoint.\n",
      "Everything Completed\n",
      "Local file has been deleted.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from office365.sharepoint.client_context import ClientContext\n",
    "from office365.sharepoint.files.file import File\n",
    "from office365.runtime.auth.client_credential import ClientCredential\n",
    "\n",
    "# SharePoint link and file details\n",
    "site_url = 'https://herbion.sharepoint.com/sites/PowerBI/'\n",
    "doc_library = '/sites/PowerBI/Shared Documents/Uzbekistan Uzum'\n",
    "file_name = 'RU-Yandex Sales.xlsx'\n",
    "\n",
    "# Client ID & Secret\n",
    "client_id = \"d244ba83-4904-4843-9043-d5da009c93ff\"\n",
    "client_secret = \"YyZ8Q~gdB5pFhxueWToWkF8c~W~WrfPmtHGU6bWp\"\n",
    "\n",
    "# Define the path to your local Excel file containing the new data\n",
    "new_data_file_path = r\"C:\\Users\\keril.batra\\OneDrive - Herbion\\Desktop\\E-Commerce\\Russia Yandex\\RU-Yandex Sales.xlsx\"\n",
    "\n",
    "# Define the columns to check for duplicates\n",
    "subset_columns = [\n",
    "    '–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞', '–î–æ—Å—Ç–∞–≤–ª–µ–Ω–æ, —à—Ç.', '–î–∞—Ç–∞ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è –∑–∞–∫–∞–∑–∞', '–°—Ç–æ–∏–º–æ—Å—Ç—å –≤—Å–µ—Ö –¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö —à—Ç—É–∫ —Å –ù–î–° –±–µ–∑ —É—á—ë—Ç–∞ —Å–∫–∏–¥–æ–∫, ‚ÇΩ']\n",
    "\n",
    "try:\n",
    "    # Authenticate using Client ID & Secret\n",
    "    credentials = ClientCredential(client_id, client_secret)\n",
    "    ctx = ClientContext(site_url).with_credentials(credentials)\n",
    "    ctx.load(ctx.web)\n",
    "    ctx.execute_query()\n",
    "    print(\"‚úÖ Connected to SharePoint:\", ctx.web.properties['Title'])\n",
    "\n",
    "    # Download the existing file from SharePoint\n",
    "    response = File.open_binary(ctx, f\"{doc_library}/{file_name}\")\n",
    "\n",
    "    # Write the response content to a local file\n",
    "    with open(file_name, \"wb\") as existing_file:\n",
    "        existing_file.write(response.content)\n",
    "\n",
    "    print(\"Existing file has been downloaded from SharePoint.\")\n",
    "\n",
    "    # Load the existing data into a DataFrame\n",
    "    try:\n",
    "        existing_df = pd.read_excel(file_name)\n",
    "        print(\"Existing data loaded into DataFrame.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading existing data: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during file download for existing data: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Load the new data into a DataFrame\n",
    "try:\n",
    "    df = pd.read_excel(new_data_file_path)\n",
    "    print(\"New data loaded into DataFrame.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading new data from the file: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Combine the existing data with the new data\n",
    "try:\n",
    "    # Combine and deduplicate based on the subset columns\n",
    "    combined_df = pd.concat([existing_df, df], ignore_index=True)\n",
    "    combined_df = combined_df.drop_duplicates(subset=subset_columns)\n",
    "    print(\"New data merged with existing data successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error while merging data: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Get the new rows added after combining\n",
    "new_rows = combined_df[len(existing_df):]\n",
    "\n",
    "if new_rows.empty:\n",
    "    print(\"No new rows to add.\")\n",
    "else:\n",
    "    # Append the new rows to the Excel sheet\n",
    "    try:\n",
    "        book = load_workbook(file_name)\n",
    "        sheet = book['–î–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã']  # Pls check that this matches your sheet name\n",
    "        for row in new_rows.itertuples(index=False, name=None):\n",
    "            sheet.append(row)\n",
    "\n",
    "        # Save the modified file\n",
    "        book.save(file_name)\n",
    "        print(\"Data has been successfully written to the Excel file without duplicates.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving the Excel file: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "    # Upload the updated file back to SharePoint\n",
    "    try:\n",
    "        with open(file_name, 'rb') as content_file:\n",
    "            file_content = content_file.read()\n",
    "\n",
    "        File.save_binary(ctx, f\"{doc_library}/{file_name}\", file_content)\n",
    "        print(\"File has been uploaded back to SharePoint.\")\n",
    "        print(\"Everything Completed\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during file upload: {e}\")\n",
    "\n",
    "# Cleanup: Remove the local file\n",
    "if os.path.exists(file_name):\n",
    "    os.remove(file_name)\n",
    "    print(\"Local file has been deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b205b406-3966-439b-802c-7f535033394b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
